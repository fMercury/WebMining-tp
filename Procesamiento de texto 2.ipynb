{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 20 newsgroups\n",
    "El dataset 20 Newsgroups es una colección de aproximadamente 20.000 documentos de grupos de noticias, particionados en 20 diferentes temas (aproximadamente balanceado).\n",
    "\n",
    "Algunos temas están bastante relacionados con otros (por ejemplo comp.sys.ibm.pc.hardware y comp.sys.mac.hardware), mientras que otros son muy diferentes (por ejemplo misc.forsale y soc.religion.christian):\n",
    "\n",
    " - comp.graphics\n",
    " - comp.os.ms-windows.misc\n",
    " - comp.sys.ibm.pc.hardware\n",
    " - comp.sys.mac.hardware\n",
    " - comp.windows.x\n",
    " \n",
    " - rec.autos\n",
    " - rec.motorcycles\n",
    " - rec.sport.baseball\n",
    " - rec.sport.hockey\tsci.crypt\n",
    " \n",
    " - sci.electronics\n",
    " - sci.med\n",
    " - sci.space\n",
    " \n",
    " - misc.forsale\n",
    " \n",
    " - talk.politics.misc\n",
    " - talk.politics.guns\n",
    " - talk.politics.mideast\n",
    " \n",
    " - talk.religion.misc\n",
    " - alt.atheism\n",
    " - soc.religion.christian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "Usamos el dataset 20 newsgroups que está disponible en la biblioteca datasets de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading the data set - training data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos chequear los nombres de las clases asociadas a cada documento con el siguiente comando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names #prints all the categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccionar las primeras lineas del primer documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:10])) #prints first 10 lines of the first data file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de características\n",
    "Los documentos deben primero pre procesarse para separar el texto en tokens y convertirlos al espacio de vectores. Básicamente se separa cada archivo de texto en palabras (separando por espacios) y se cuenta la cantidad de veces que ocurre cada palabra en el documento. Finalmente se le asigna a cada palabra un identificador entero.\n",
    "La clase CountVectorizer es la encargada de crear los vectores de características.\n",
    "El método fit_transform aprende el vocabulario y retorna una matriz Document-Term [#documentos, #features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 86580)\t1\n",
      "  (0, 128420)\t1\n",
      "  (0, 35983)\t1\n",
      "  (0, 35187)\t1\n",
      "  (0, 66098)\t1\n",
      "  (0, 114428)\t1\n",
      "  (0, 78955)\t1\n",
      "  (0, 94362)\t1\n",
      "  (0, 76722)\t1\n",
      "  (0, 57308)\t1\n",
      "  (0, 62221)\t1\n",
      "  (0, 128402)\t2\n",
      "  (0, 67156)\t1\n",
      "  (0, 123989)\t1\n",
      "  (0, 90252)\t1\n",
      "  (0, 63363)\t1\n",
      "  (0, 78784)\t1\n",
      "  (0, 96144)\t1\n",
      "  (0, 128026)\t1\n",
      "  (0, 109271)\t1\n",
      "  (0, 51730)\t1\n",
      "  (0, 86001)\t1\n",
      "  (0, 83256)\t1\n",
      "  (0, 113986)\t1\n",
      "  (0, 37565)\t1\n",
      "  :\t:\n",
      "  (0, 4605)\t1\n",
      "  (0, 76032)\t1\n",
      "  (0, 92081)\t1\n",
      "  (0, 40998)\t1\n",
      "  (0, 79666)\t1\n",
      "  (0, 89362)\t3\n",
      "  (0, 118983)\t1\n",
      "  (0, 90379)\t1\n",
      "  (0, 98949)\t1\n",
      "  (0, 64095)\t1\n",
      "  (0, 95162)\t1\n",
      "  (0, 87620)\t1\n",
      "  (0, 114731)\t5\n",
      "  (0, 68532)\t3\n",
      "  (0, 37780)\t5\n",
      "  (0, 123984)\t1\n",
      "  (0, 111322)\t1\n",
      "  (0, 114688)\t1\n",
      "  (0, 85354)\t1\n",
      "  (0, 124031)\t2\n",
      "  (0, 50527)\t2\n",
      "  (0, 118280)\t2\n",
      "  (0, 123162)\t2\n",
      "  (0, 75358)\t2\n",
      "  (0, 56979)\t3\n"
     ]
    }
   ],
   "source": [
    "# Extracting features from text files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "\n",
    "X_train_counts.shape\n",
    "print(X_train_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37780"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count_vect.vocabulary_.get('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESIÓN LINEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINES (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear')\n",
    "svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos un clasificador Naive Bayes (NB) a partir de los datos de entrenamiento\n",
    "\n",
    "Para entrenar, todos los clasificadores poseen el método **fit** que recibe los ejemplos de entrenamiento como primer parámetro y las clases asociadas a cada uno en el segundo parámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos un pipeline con todo el proceso. Los nombres 'vect', 'tfidf' y 'clf' son arbitrarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB(alpha=1.0))])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar el clasificador para identificar la clase de un conjunto de documentos nuevos se utiliza el método **predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 15  2]\n",
      "7  =  rec.autos\n",
      "15  =  soc.religion.christian\n",
      "2  =  comp.os.ms-windows.misc\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(['This is a beautiful car','I love god','I love mac and hate windows'])\n",
    "print (predicted)\n",
    "for i in predicted:\n",
    "    print (i,\" = \",twenty_train.target_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos la eficiencia del clasificador con un conjunto de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases identificadas :  [ 7 11  0 ...  9  3 15]\n",
      "Clases reales del doc:  [ 7  5  0 ...  9  6 15]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7738980350504514"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "print (\"Clases identificadas : \", predicted)\n",
    "print (\"Clases reales del doc: \", twenty_test.target)\n",
    "\n",
    "import numpy as np\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True, False,  True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted == twenty_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probamos con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8238183749336165"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
    "np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación de parámetros\n",
    "\n",
    "GridSearch nos permite crear una lista de parámetros para los cuales queremos evaluar la eficacia de un clasificador.\n",
    "\n",
    "Todos los parámetros deben comenzar con el nombre del clasificador (recordar que le dimos un nombre arbitrario\n",
    "\n",
    "Por ejemplo vect__ngram_range indica que vamos a usar unigramas y bigramas y que elija el que arroja mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos una instancia de grid search pasando el clasificador, los parámetros y n_jobs=-1 que indica que use todos los cores disponibles de la máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver los mejores scores y los parámetros corremos el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9067526957751458"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el accuracy se incrementó a 90.6% para el clasificador bayesiano y los parámetros ‘alpha’: 0.01 del clasificador y  ‘use_idf’: True, ‘ngram_range’: (1, 2) del pre-procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos lo mismo para SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), \n",
    "                     ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "No está incluido en sklearn, pero se puede realizar customizando el Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8114710568242167"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
    "                             ('mnb', MultinomialNB())])\n",
    "\n",
    "text_mnb_stemmed = text_mnb_stemmed.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(twenty_test.data)\n",
    "\n",
    "import numpy as np\n",
    "np.mean(predicted_mnb_stemmed == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    " - Es una biblioteca especializada en procesamiento de lenguaje natural\n",
    " - Recursos léxicos\n",
    " - Tokenización de palabras y oraciones\n",
    " - PoS Tagging\n",
    " - Identificación de entidades nombradas (NER)\n",
    " - Técnicas de minería de texto (por ejemplo clasificación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumed!', 'where?', 'Over the lazy dog.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "text = 'The quick brown fox jumed! where? Over the lazy dog.'\n",
    "sentences = sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'jumed', '!']\n",
      "['where', '?']\n",
      "['Over', 'the', 'lazy', 'dog', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    words = word_tokenize(sentence)\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciona para texto de redes sociales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', 'mg_armentano', ':', 'an', 'example', '!', ':', 'D', 'http', ':', '//example.com', '#', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "tweet = '@mg_armentano: an example! :D http://example.com #NLP'\n",
    "print(word_tokenize(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@mg_armentano', ':', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "tweet = '@mg_armentano: an example! :D http://example.com #NLP'\n",
    "print(tokenizer.tokenize(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textos de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "text1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptualmente, un objeto **nltk.text** no es más que una lista ordenada de tokens, siendo esto la unidad mínima de un texto, simplemente palabras o signos de puntuación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de textos desde url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "448614\n",
      "﻿Project Gutenberg's A Journey to the Interior of the Earth, by Jules Verne\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "url = \"http://www.gutenberg.org/cache/epub/3748/pg3748.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "\n",
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print(raw[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "91752\n",
      "['\\ufeffProject', 'Gutenberg', \"'s\", 'A', 'Journey', 'to', 'the', 'Interior', 'of', 'the']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(len(tokens))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "91752\n",
      "['\\ufeffProject', 'Gutenberg', \"'s\", 'A', 'Journey', 'to', 'the', 'Interior', 'of', 'the']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(len(text))\n",
    "print(text[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda con contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 120 matches:\n",
      "cry , `` Thalatta ! thalatta ! '' the sea ! the sea ! The deeply indented shore\n",
      "halatta ! thalatta ! '' the sea ! the sea ! The deeply indented shore was lined\n",
      "ood , changeable , mother , bow , and sea ? The first and the last might have s\n",
      " Iceland there should be mention of a sea of ice ; but it was quite another thi\n",
      "`` Yes ; a mountain rising out of the sea . '' `` Right . That is Snæfell . '' \n",
      "urs we stopped at Kiel , close to the sea . The luggage being labelled for Cope\n",
      " there was a sharp breeze and a rough sea , a few lights appeared on shore thro\n",
      "t . At last he discerned a stretch of sea . `` The Sound ! '' he cried . At our\n",
      "arts , whose huge arms dilated in the sea breeze like the sails of a ship . Wha\n",
      " the green country , on the other the sea sparkled , bathed in sunlight . The S\n",
      "Cape Lindness , and entered the North Sea . In two days more we sighted the coa\n",
      " unusual . I bore the troubles of the sea pretty well ; my uncle , to his own i\n",
      "s perforated rock , through which the sea dashed furiously . The Westman islets\n",
      " western point of Iceland . The rough sea prevented my uncle from coming on dec\n",
      "e side , and falls gently towards the sea . On the other extends the vast bay o\n",
      "o the peninsula of Snæfell ? '' `` By sea , crossing the bay . That 's the most\n",
      "oth terraced rocks which slope to the sea , the Icelandic hunter might exercise\n",
      "f barren rocks made a dip towards the sea , and encroached upon the scanty past\n",
      "left between a chain of hills and the sea , they carried us to our next stage ,\n",
      " it on horseback across an arm of the sea . If they are as intelligent as they \n",
      "he crossing of the fiord , when , the sea having reached its greatest height , \n",
      "arried either to the bottom or out to sea . That favourable moment arrived only\n",
      "d pull off the rocks and a few meagre sea weeds , and the next day they would n\n",
      ". we reached Büdir , a village on the sea shore ; and the guide there claiming \n",
      " of which formed a semi-arch over the sea . At intervals , under this natural s\n"
     ]
    }
   ],
   "source": [
    "text.concordance(\"sea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener colocaciones\n",
    "Las colocaciones son unidades fraseológicas de dos o más palabras que se usan muy habitualmente combinadas, más de lo que probabilísticamente se daría. Por ejemplo, en español \"alto riesgo\", \"sin duda\", \"no hay problema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Gutenberg-tm; Project Gutenberg; Professor Liedenbrock;\n",
      "Literary Archive; Gutenberg-tm electronic; Archive Foundation;\n",
      "electronic works; Jules Verne; United States; Gutenberg Literary; Arne\n",
      "Saknussemm; hundred feet; Humphry Davy; public domain; next day; Port\n",
      "Gräuben; electronic work; sixteenth century; Gutenberg-tm License; set\n",
      "forth\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similitud distribucional\n",
    "Permite buscar palabras que aparecen en los mismos contextos de una palabra dada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earth professor raft world water way air rocks globe work time crater\n",
      "waves rock compass journey shore ground gallery soil\n"
     ]
    }
   ],
   "source": [
    "text.similar(\"sea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras más comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Professor', 164), ('should', 97), ('little', 94), ('seemed', 90), ('before', 86), ('through', 84), ('Project', 82), ('without', 82), ('myself', 81), ('hundred', 77), ('moment', 72), ('thought', 70), ('nothing', 69), ('Liedenbrock', 66), ('replied', 66), ('surface', 64), ('leagues', 60), ('Gutenberg-tm', 55), ('against', 54), ('Iceland', 53), ('therefore', 53), ('granite', 51), ('CHAPTER', 45), ('Snæfell', 44), ('course', 43), ('Saknussemm', 43), ('between', 42), ('gallery', 42), ('looked', 40), ('passed', 39), ('almost', 37), ('enough', 37), ('Gräuben', 37), ('crater', 37), ('thousand', 36), ('centre', 36), ('himself', 35), ('reason', 35), ('rather', 35), ('return', 34), ('called', 34), ('reached', 34), ('matter', 32), ('formed', 32), ('silence', 32), ('period', 31), ('question', 31), ('carried', 31), ('together', 30), ('distance', 30), ('Icelandic', 30), ('document', 30), ('within', 30), ('passage', 30), ('certain', 29), ('longer', 29), ('hunter', 29), ('journey', 28), ('became', 28), ('another', 28), ('mountain', 28), ('compass', 28), ('Gutenberg', 27), ('island', 27), ('morning', 27), ('believe', 27), ('electronic', 27), ('learned', 26), ('nature', 26), ('brought', 26), ('letters', 26), ('followed', 26), ('answer', 25), ('volcano', 25), ('action', 25), ('waters', 25), ('stopped', 25), ('following', 24), ('science', 24), ('scarcely', 24), ('Martha', 24), ('appeared', 24), ('minutes', 24), ('returned', 24), ('immense', 24), ('Foundation', 24), ('arrived', 23), ('answered', 23), ('electric', 23), ('scientific', 22), ('appearance', 22), ('wanted', 22), ('become', 22), ('coming', 22), ('degrees', 22), ('around', 22), ('darkness', 22), ('obliged', 22), ('temperature', 22), ('liquid', 22), ('distant', 22), ('ground', 22), ('farther', 22), ('Hamburg', 21), ('others', 21), ('instead', 21), ('beginning', 21), ('repeated', 21), ('impossible', 21), ('amongst', 21), ('pressure', 21), ('enormous', 21), ('things', 20), ('having', 20), ('Rejkiavik', 20), ('ourselves', 20), ('better', 20), ('stream', 20), ('evening', 20), ('Fridrikssen', 20), ('descent', 20), ('height', 20), ('living', 19), ('strange', 19), ('difficulty', 19), ('already', 19), ('strength', 19), ('extinct', 19), ('eruption', 19), ('central', 19), ('Danish', 19), ('country', 19)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "fdist1 = FreqDist(text)\n",
    "print([i for i in fdist1.most_common(500) if len(i[0]) > 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otras funciones interesantes de FreqDist\n",
    "\n",
    " - fdist.values(): Devuelve la cantidad de veces que aparece cada palabra\n",
    " - fdist.N(): Total de palabras en el texto\n",
    " - fdist[word]: Cantidad de ocurrencias de word\n",
    " - fdist.freq(word): Devuelve la frecuencia de aparación de word\n",
    " - fdist.max(): Palabra con máxima frecuencia\n",
    " - fdist.plot(): Representación gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1a2fcb278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "fdist1.plot(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersión de una palabra\n",
    "Podemos también ver gráficamente como evoluciona la aparición de una palabra a lo largo del documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1f9066550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text.dispersion_plot([\"Sea\", \"Earth\", \"Professor\",\"little\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\ufeffProject', 'Gutenberg'),\n",
       " ('Gutenberg', \"'s\"),\n",
       " (\"'s\", 'A'),\n",
       " ('A', 'Journey'),\n",
       " ('Journey', 'to'),\n",
       " ('to', 'the'),\n",
       " ('the', 'Interior'),\n",
       " ('Interior', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'Earth'),\n",
       " ('Earth', ','),\n",
       " (',', 'by'),\n",
       " ('by', 'Jules'),\n",
       " ('Jules', 'Verne'),\n",
       " ('Verne', 'This')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams(text))[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffproject',\n",
       " 'gutenberg',\n",
       " \"'s\",\n",
       " 'A',\n",
       " 'journey',\n",
       " 'to',\n",
       " 'the',\n",
       " 'interior',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " ',',\n",
       " 'by',\n",
       " 'jule',\n",
       " 'vern',\n",
       " 'thi',\n",
       " 'ebook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "list(porter.stem(t) for t in tokens)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffproject',\n",
       " 'gutenberg',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'journey',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intery',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ear',\n",
       " ',',\n",
       " 'by',\n",
       " 'jul',\n",
       " 'vern',\n",
       " 'thi',\n",
       " 'ebook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster = nltk.LancasterStemmer()\n",
    "list(lancaster.stem(t) for t in tokens)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematización\n",
    "A diferencia del stemming, el lematizador solo elimina el final de la palabra si la palabra resultante se encuentra en el diccionario. Esto lo hace un proceso más lento que el stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffProject',\n",
       " 'Gutenberg',\n",
       " \"'s\",\n",
       " 'A',\n",
       " 'Journey',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Interior',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Earth',\n",
       " ',',\n",
       " 'by',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " 'This',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restriction',\n",
       " 'whatsoever',\n",
       " '.',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it',\n",
       " ',',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'term',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License',\n",
       " 'included',\n",
       " 'with',\n",
       " 'this',\n",
       " 'eBook',\n",
       " 'or',\n",
       " 'online',\n",
       " 'at',\n",
       " 'www.gutenberg.org',\n",
       " 'Title',\n",
       " ':',\n",
       " 'A',\n",
       " 'Journey',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Interior',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Earth',\n",
       " 'Author',\n",
       " ':',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " 'Posting',\n",
       " 'Date',\n",
       " ':',\n",
       " 'December',\n",
       " '3',\n",
       " ',',\n",
       " '2010',\n",
       " '[',\n",
       " 'EBook',\n",
       " '#',\n",
       " '3748',\n",
       " ']',\n",
       " 'Release',\n",
       " 'Date',\n",
       " ':',\n",
       " 'February',\n",
       " ',',\n",
       " '2003',\n",
       " '[',\n",
       " 'Last',\n",
       " 'updated',\n",
       " ':',\n",
       " 'August',\n",
       " '19',\n",
       " ',',\n",
       " '2011',\n",
       " ']',\n",
       " 'Language',\n",
       " ':',\n",
       " 'English',\n",
       " '***',\n",
       " 'START',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " 'EBOOK',\n",
       " 'A',\n",
       " 'JOURNEY',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'INTERIOR',\n",
       " '***',\n",
       " 'Produced',\n",
       " 'by',\n",
       " 'Norman',\n",
       " 'M.',\n",
       " 'Wolcott',\n",
       " '.',\n",
       " 'A',\n",
       " 'Journey',\n",
       " 'into',\n",
       " 'the',\n",
       " 'Interior',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Earth',\n",
       " 'by',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " '[',\n",
       " 'Redactor',\n",
       " \"'s\",\n",
       " 'Note',\n",
       " ':',\n",
       " 'The',\n",
       " 'following',\n",
       " 'version',\n",
       " 'of',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " \"'s\",\n",
       " '``',\n",
       " 'Journey',\n",
       " 'into',\n",
       " 'the',\n",
       " 'Interior',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Earth',\n",
       " \"''\",\n",
       " 'wa',\n",
       " 'published',\n",
       " 'by',\n",
       " 'Ward',\n",
       " ',',\n",
       " 'Lock',\n",
       " ',',\n",
       " '&',\n",
       " 'Co.',\n",
       " ',',\n",
       " 'Ltd.',\n",
       " ',',\n",
       " 'London',\n",
       " ',',\n",
       " 'in',\n",
       " '1877',\n",
       " '.',\n",
       " 'This',\n",
       " 'version',\n",
       " 'is',\n",
       " 'believed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " 'most',\n",
       " 'faithful',\n",
       " 'rendition',\n",
       " 'into',\n",
       " 'English',\n",
       " 'of',\n",
       " 'this',\n",
       " 'classic',\n",
       " 'currently',\n",
       " 'in',\n",
       " 'the',\n",
       " 'public',\n",
       " 'domain',\n",
       " '.',\n",
       " 'The',\n",
       " 'few',\n",
       " 'note',\n",
       " 'of',\n",
       " 'the',\n",
       " 'translator',\n",
       " 'are',\n",
       " 'located',\n",
       " 'near',\n",
       " 'the',\n",
       " 'point',\n",
       " 'where',\n",
       " 'they',\n",
       " 'are',\n",
       " 'referenced',\n",
       " '.',\n",
       " 'The',\n",
       " 'Runic',\n",
       " 'character',\n",
       " 'in',\n",
       " 'Chapter',\n",
       " 'III',\n",
       " 'are',\n",
       " 'visible',\n",
       " 'in',\n",
       " 'the',\n",
       " 'HTML',\n",
       " 'version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'text',\n",
       " '.',\n",
       " 'The',\n",
       " 'character',\n",
       " 'set',\n",
       " 'is',\n",
       " 'ISO-8891-1',\n",
       " ',',\n",
       " 'mainly',\n",
       " 'the',\n",
       " 'Windows',\n",
       " 'character',\n",
       " 'set',\n",
       " '.',\n",
       " 'The',\n",
       " 'translation',\n",
       " 'is',\n",
       " 'by',\n",
       " 'Frederick',\n",
       " 'Amadeus',\n",
       " 'Malleson',\n",
       " '.',\n",
       " 'While',\n",
       " 'the',\n",
       " 'translation',\n",
       " 'is',\n",
       " 'fairly',\n",
       " 'literal',\n",
       " ',',\n",
       " 'and',\n",
       " 'Malleson',\n",
       " '(',\n",
       " 'a',\n",
       " 'clergyman',\n",
       " ')',\n",
       " 'ha',\n",
       " 'taken',\n",
       " 'pain',\n",
       " 'with',\n",
       " 'the',\n",
       " 'scientific',\n",
       " 'portion',\n",
       " 'of',\n",
       " 'the',\n",
       " 'work',\n",
       " 'and',\n",
       " 'added',\n",
       " 'the',\n",
       " 'chapter',\n",
       " 'heading',\n",
       " ',',\n",
       " 'he',\n",
       " 'ha',\n",
       " 'made',\n",
       " 'some',\n",
       " 'unfortunate',\n",
       " 'emendation',\n",
       " 'mainly',\n",
       " 'concerning',\n",
       " 'biblical',\n",
       " 'reference',\n",
       " ',',\n",
       " 'and',\n",
       " 'ha',\n",
       " 'added',\n",
       " 'a',\n",
       " 'few',\n",
       " \"'improvements\",\n",
       " \"'\",\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " ',',\n",
       " 'which',\n",
       " 'are',\n",
       " 'detailed',\n",
       " 'below',\n",
       " ':',\n",
       " 'III',\n",
       " '.',\n",
       " '``',\n",
       " '_pertubata',\n",
       " 'seu',\n",
       " 'inordinata',\n",
       " ',',\n",
       " '_',\n",
       " \"''\",\n",
       " 'a',\n",
       " 'Euclid',\n",
       " 'ha',\n",
       " 'it',\n",
       " '.',\n",
       " \"''\",\n",
       " 'XXX',\n",
       " '.',\n",
       " 'cry',\n",
       " ',',\n",
       " '``',\n",
       " 'Thalatta',\n",
       " '!',\n",
       " 'thalatta',\n",
       " '!',\n",
       " \"''\",\n",
       " 'the',\n",
       " 'sea',\n",
       " '!',\n",
       " 'the',\n",
       " 'sea',\n",
       " '!',\n",
       " 'The',\n",
       " 'deeply',\n",
       " 'indented',\n",
       " 'shore',\n",
       " 'wa',\n",
       " 'lined',\n",
       " 'with',\n",
       " 'a',\n",
       " 'breadth',\n",
       " 'of',\n",
       " 'fine',\n",
       " 'shining',\n",
       " 'sand',\n",
       " ',',\n",
       " 'softly',\n",
       " 'XXXII',\n",
       " '.',\n",
       " 'hippopotamus',\n",
       " '.',\n",
       " '{',\n",
       " 'a',\n",
       " 'if',\n",
       " 'the',\n",
       " 'creator',\n",
       " ',',\n",
       " 'pressed',\n",
       " 'for',\n",
       " 'time',\n",
       " 'in',\n",
       " 'the',\n",
       " 'first',\n",
       " 'hour',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'had',\n",
       " 'assembled',\n",
       " 'several',\n",
       " 'animal',\n",
       " 'into',\n",
       " 'one',\n",
       " '.',\n",
       " '}',\n",
       " 'The',\n",
       " 'colossal',\n",
       " 'mastodon',\n",
       " 'XXXII',\n",
       " '.',\n",
       " 'I',\n",
       " 'return',\n",
       " 'to',\n",
       " 'the',\n",
       " 'scriptural',\n",
       " 'period',\n",
       " 'or',\n",
       " 'age',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'conventionally',\n",
       " 'called',\n",
       " \"'days\",\n",
       " ',',\n",
       " \"'\",\n",
       " 'long',\n",
       " 'before',\n",
       " 'the',\n",
       " 'appearance',\n",
       " 'of',\n",
       " 'man',\n",
       " 'when',\n",
       " 'the',\n",
       " 'unfinished',\n",
       " 'world',\n",
       " 'wa',\n",
       " 'a',\n",
       " 'yet',\n",
       " 'unfitted',\n",
       " 'for',\n",
       " 'his',\n",
       " 'support',\n",
       " '.',\n",
       " '{',\n",
       " 'I',\n",
       " 'return',\n",
       " 'to',\n",
       " 'the',\n",
       " 'biblical',\n",
       " 'epoch',\n",
       " 'of',\n",
       " 'the',\n",
       " 'creation',\n",
       " ',',\n",
       " 'well',\n",
       " 'in',\n",
       " 'advance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'birth',\n",
       " 'of',\n",
       " 'man',\n",
       " ',',\n",
       " 'when',\n",
       " 'the',\n",
       " 'incomplete',\n",
       " 'earth',\n",
       " 'wa',\n",
       " 'not',\n",
       " 'yet',\n",
       " 'sufficient',\n",
       " 'for',\n",
       " 'him',\n",
       " '.',\n",
       " '}',\n",
       " 'XXXVIII',\n",
       " '.',\n",
       " '(',\n",
       " 'footnote',\n",
       " ')',\n",
       " ',',\n",
       " 'and',\n",
       " 'which',\n",
       " 'is',\n",
       " 'illustrated',\n",
       " 'in',\n",
       " 'the',\n",
       " 'negro',\n",
       " 'countenance',\n",
       " 'and',\n",
       " 'in',\n",
       " 'the',\n",
       " 'lowest',\n",
       " 'savage',\n",
       " '.',\n",
       " 'XXXIX',\n",
       " '.',\n",
       " 'of',\n",
       " 'the',\n",
       " 'geologic',\n",
       " 'period',\n",
       " '.',\n",
       " '{',\n",
       " 'antediluvian',\n",
       " '}',\n",
       " '(',\n",
       " 'These',\n",
       " 'correction',\n",
       " 'have',\n",
       " 'kindly',\n",
       " 'been',\n",
       " 'pointed',\n",
       " 'out',\n",
       " 'by',\n",
       " 'Christian',\n",
       " 'Sánchez',\n",
       " '<',\n",
       " 'chvsanchez',\n",
       " '@',\n",
       " 'arnet.com.ar',\n",
       " '>',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " 'Forum',\n",
       " '.',\n",
       " ')',\n",
       " ']',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " 'A',\n",
       " 'JOURNEY',\n",
       " 'INTO',\n",
       " 'THE',\n",
       " 'INTERIOR',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'EARTH',\n",
       " 'by',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " 'PREFACE',\n",
       " 'THE',\n",
       " '``',\n",
       " 'Voyages',\n",
       " 'Extraordinaires',\n",
       " \"''\",\n",
       " 'of',\n",
       " 'M.',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " 'deserve',\n",
       " 'to',\n",
       " 'be',\n",
       " 'made',\n",
       " 'widely',\n",
       " 'known',\n",
       " 'in',\n",
       " 'English-speaking',\n",
       " 'country',\n",
       " 'by',\n",
       " 'mean',\n",
       " 'of',\n",
       " 'carefully',\n",
       " 'prepared',\n",
       " 'translation',\n",
       " '.',\n",
       " 'Witty',\n",
       " 'and',\n",
       " 'ingenious',\n",
       " 'adaptation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'research',\n",
       " 'and',\n",
       " 'discovery',\n",
       " 'of',\n",
       " 'modern',\n",
       " 'science',\n",
       " 'to',\n",
       " 'the',\n",
       " 'popular',\n",
       " 'taste',\n",
       " ',',\n",
       " 'which',\n",
       " 'demand',\n",
       " 'that',\n",
       " 'these',\n",
       " 'should',\n",
       " 'be',\n",
       " 'presented',\n",
       " 'to',\n",
       " 'ordinary',\n",
       " 'reader',\n",
       " 'in',\n",
       " 'the',\n",
       " 'lighter',\n",
       " 'form',\n",
       " 'of',\n",
       " 'cleverly',\n",
       " 'mingled',\n",
       " 'truth',\n",
       " 'and',\n",
       " 'fiction',\n",
       " ',',\n",
       " 'these',\n",
       " 'book',\n",
       " 'will',\n",
       " 'assuredly',\n",
       " 'be',\n",
       " 'read',\n",
       " 'with',\n",
       " 'profit',\n",
       " 'and',\n",
       " 'delight',\n",
       " ',',\n",
       " 'especially',\n",
       " 'by',\n",
       " 'English',\n",
       " 'youth',\n",
       " '.',\n",
       " 'Certainly',\n",
       " 'no',\n",
       " 'writer',\n",
       " 'before',\n",
       " 'M.',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " 'ha',\n",
       " 'been',\n",
       " 'so',\n",
       " 'happy',\n",
       " 'in',\n",
       " 'weaving',\n",
       " 'together',\n",
       " 'in',\n",
       " 'judicious',\n",
       " 'combination',\n",
       " 'severe',\n",
       " 'scientific',\n",
       " 'truth',\n",
       " 'with',\n",
       " 'a',\n",
       " 'charming',\n",
       " 'exercise',\n",
       " 'of',\n",
       " 'playful',\n",
       " 'imagination',\n",
       " '.',\n",
       " 'Iceland',\n",
       " ',',\n",
       " 'the',\n",
       " 'starting',\n",
       " 'point',\n",
       " 'of',\n",
       " 'the',\n",
       " 'marvellous',\n",
       " 'underground',\n",
       " 'journey',\n",
       " 'imagined',\n",
       " 'in',\n",
       " 'this',\n",
       " 'volume',\n",
       " ',',\n",
       " 'is',\n",
       " 'invested',\n",
       " 'at',\n",
       " 'the',\n",
       " 'present',\n",
       " 'time',\n",
       " 'with',\n",
       " 'a',\n",
       " 'painful',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'consequence',\n",
       " 'of',\n",
       " 'the',\n",
       " 'disastrous',\n",
       " 'eruption',\n",
       " 'last',\n",
       " 'Easter',\n",
       " 'Day',\n",
       " ',',\n",
       " 'which',\n",
       " 'covered',\n",
       " 'with',\n",
       " 'lava',\n",
       " 'and',\n",
       " 'ash',\n",
       " 'the',\n",
       " 'poor',\n",
       " 'and',\n",
       " 'scanty',\n",
       " 'vegetation',\n",
       " 'upon',\n",
       " 'which',\n",
       " 'four',\n",
       " 'thousand',\n",
       " 'person',\n",
       " 'were',\n",
       " 'partly',\n",
       " 'dependent',\n",
       " 'for',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'of',\n",
       " 'subsistence',\n",
       " '.',\n",
       " 'For',\n",
       " 'a',\n",
       " 'long',\n",
       " 'time',\n",
       " 'to',\n",
       " 'come',\n",
       " 'the',\n",
       " 'native',\n",
       " 'of',\n",
       " 'that',\n",
       " 'interesting',\n",
       " 'island',\n",
       " ',',\n",
       " 'who',\n",
       " 'cleave',\n",
       " 'to',\n",
       " 'their',\n",
       " 'desert',\n",
       " 'home',\n",
       " 'with',\n",
       " 'all',\n",
       " 'that',\n",
       " '_amor',\n",
       " 'patriae_',\n",
       " 'which',\n",
       " 'is',\n",
       " 'so',\n",
       " 'much',\n",
       " 'more',\n",
       " 'easily',\n",
       " 'understood',\n",
       " 'than',\n",
       " 'explained',\n",
       " ',',\n",
       " 'will',\n",
       " 'look',\n",
       " ',',\n",
       " 'and',\n",
       " 'look',\n",
       " 'not',\n",
       " 'in',\n",
       " 'vain',\n",
       " ',',\n",
       " 'for',\n",
       " 'the',\n",
       " 'help',\n",
       " 'of',\n",
       " 'those',\n",
       " 'on',\n",
       " 'whom',\n",
       " 'fall',\n",
       " 'the',\n",
       " 'smile',\n",
       " 'of',\n",
       " 'a',\n",
       " 'kindlier',\n",
       " 'sun',\n",
       " 'in',\n",
       " 'region',\n",
       " 'not',\n",
       " 'torn',\n",
       " 'by',\n",
       " 'earthquake',\n",
       " 'nor',\n",
       " 'blasted',\n",
       " 'and',\n",
       " 'ravaged',\n",
       " 'by',\n",
       " 'volcanic',\n",
       " 'fire',\n",
       " '.',\n",
       " 'Will',\n",
       " 'the',\n",
       " 'reader',\n",
       " 'of',\n",
       " 'this',\n",
       " 'little',\n",
       " 'book',\n",
       " ',',\n",
       " 'who',\n",
       " ',',\n",
       " 'are',\n",
       " 'gifted',\n",
       " 'with',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'of',\n",
       " 'indulging',\n",
       " 'in',\n",
       " 'the',\n",
       " 'luxury',\n",
       " 'of',\n",
       " 'extended',\n",
       " 'beneficence',\n",
       " ',',\n",
       " 'remember',\n",
       " 'the',\n",
       " 'distress',\n",
       " 'of',\n",
       " 'their',\n",
       " 'brother',\n",
       " 'in',\n",
       " 'the',\n",
       " 'far',\n",
       " 'north',\n",
       " ',',\n",
       " 'whom',\n",
       " 'distance',\n",
       " 'ha',\n",
       " 'not',\n",
       " 'barred',\n",
       " 'from',\n",
       " 'the',\n",
       " 'claim',\n",
       " 'of',\n",
       " 'being',\n",
       " 'counted',\n",
       " 'our',\n",
       " '``',\n",
       " 'neighbour',\n",
       " \"''\",\n",
       " '?',\n",
       " 'And',\n",
       " 'whatever',\n",
       " 'their',\n",
       " 'humane',\n",
       " 'feeling',\n",
       " 'may',\n",
       " 'prompt',\n",
       " 'them',\n",
       " 'to',\n",
       " 'bestow',\n",
       " 'will',\n",
       " 'be',\n",
       " 'gladly',\n",
       " 'added',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Mansion-House',\n",
       " 'Iceland',\n",
       " 'Relief',\n",
       " 'Fund',\n",
       " '.',\n",
       " 'In',\n",
       " 'his',\n",
       " 'desire',\n",
       " 'to',\n",
       " 'ascertain',\n",
       " 'how',\n",
       " 'far',\n",
       " 'the',\n",
       " 'picture',\n",
       " 'of',\n",
       " 'Iceland',\n",
       " ',',\n",
       " 'drawn',\n",
       " 'in',\n",
       " 'the',\n",
       " 'work',\n",
       " 'of',\n",
       " 'Jules',\n",
       " 'Verne',\n",
       " 'is',\n",
       " 'a',\n",
       " 'correct',\n",
       " 'one',\n",
       " ',',\n",
       " 'the',\n",
       " 'translator',\n",
       " 'hope',\n",
       " 'in',\n",
       " 'the',\n",
       " 'course',\n",
       " 'of',\n",
       " 'a',\n",
       " 'mail',\n",
       " 'or',\n",
       " 'two',\n",
       " 'to',\n",
       " 'receive',\n",
       " 'a',\n",
       " 'communication',\n",
       " 'from',\n",
       " 'a',\n",
       " 'leading',\n",
       " 'man',\n",
       " 'of',\n",
       " 'science',\n",
       " 'in',\n",
       " 'the',\n",
       " 'island',\n",
       " ',',\n",
       " 'which',\n",
       " 'may',\n",
       " 'furnish',\n",
       " 'matter',\n",
       " 'for',\n",
       " 'additional',\n",
       " 'information',\n",
       " 'in',\n",
       " 'a',\n",
       " 'future',\n",
       " 'edition',\n",
       " '.',\n",
       " 'The',\n",
       " 'scientific',\n",
       " 'portion',\n",
       " 'of',\n",
       " 'the',\n",
       " 'French',\n",
       " 'original',\n",
       " 'is',\n",
       " 'not',\n",
       " 'without',\n",
       " 'a',\n",
       " 'few',\n",
       " 'error',\n",
       " ',',\n",
       " 'which',\n",
       " 'the',\n",
       " 'translator',\n",
       " ',',\n",
       " 'with',\n",
       " 'the',\n",
       " 'kind',\n",
       " 'assistance',\n",
       " 'of',\n",
       " 'Mr.',\n",
       " 'Cameron',\n",
       " 'of',\n",
       " 'H.',\n",
       " 'M.',\n",
       " 'Geological',\n",
       " 'Survey',\n",
       " ',',\n",
       " 'ha',\n",
       " 'ventured',\n",
       " 'to',\n",
       " 'point',\n",
       " 'out',\n",
       " 'and',\n",
       " 'correct',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'scarcely',\n",
       " 'to',\n",
       " 'be',\n",
       " ...]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "[wnl.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion_matrix(y_true, y_pred) calcula la matriz de confusión a partir de las clases reales y las predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[211,   0,   0,   1,   0,   1,   0,   1,   1,   1,   1,   3,   0,\n",
       "          6,   4,  71,   5,  11,   0,   2],\n",
       "       [  1, 279,  12,  10,   9,  21,   3,   2,   0,   4,   0,  20,   9,\n",
       "          1,  11,   3,   2,   2,   0,   0],\n",
       "       [  0,  21, 271,  40,   6,  15,   1,   1,   3,   4,   2,  18,   1,\n",
       "          0,   6,   3,   2,   0,   0,   0],\n",
       "       [  0,   6,  17, 312,  14,   3,   8,   3,   1,   0,   2,   7,  13,\n",
       "          0,   6,   0,   0,   0,   0,   0],\n",
       "       [  0,   2,   7,  19, 316,   1,   8,   6,   0,   2,   2,   8,   8,\n",
       "          1,   3,   0,   2,   0,   0,   0],\n",
       "       [  1,  28,  12,  12,   3, 312,   1,   0,   1,   1,   0,  14,   0,\n",
       "          1,   5,   2,   2,   0,   0,   0],\n",
       "       [  0,   3,   3,  32,  12,   0, 292,  16,   5,   1,   5,   2,   7,\n",
       "          6,   2,   3,   1,   0,   0,   0],\n",
       "       [  0,   1,   0,   1,   0,   0,   4, 367,   4,   2,   2,   3,   4,\n",
       "          1,   2,   0,   4,   0,   1,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   3,   9, 382,   0,   0,   1,   1,\n",
       "          0,   0,   0,   1,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   2,   3,   0, 366,  20,   0,   0,\n",
       "          0,   2,   1,   1,   1,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   3, 391,   1,   0,\n",
       "          0,   1,   3,   0,   0,   0,   0],\n",
       "       [  0,   2,   1,   0,   0,   1,   1,   3,   1,   1,   0, 384,   1,\n",
       "          0,   0,   0,   1,   0,   0,   0],\n",
       "       [  0,   6,   4,  21,   6,   0,   6,   6,   7,   1,   1,  53, 258,\n",
       "          4,  11,   6,   1,   2,   0,   0],\n",
       "       [  2,   1,   0,   2,   1,   3,   2,   0,   4,   5,   6,   6,   7,\n",
       "        314,   7,  27,   4,   4,   1,   0],\n",
       "       [  0,   5,   0,   0,   0,   3,   0,   1,   1,   0,   0,   3,   1,\n",
       "          2, 371,   5,   1,   0,   1,   0],\n",
       "       [  2,   1,   1,   1,   0,   0,   0,   1,   1,   0,   0,   0,   1,\n",
       "          1,   2, 386,   0,   0,   0,   1],\n",
       "       [  0,   0,   0,   1,   0,   0,   2,   0,   2,   1,   1,   6,   0,\n",
       "          1,   1,   3, 343,   2,   1,   0],\n",
       "       [  0,   1,   0,   0,   0,   1,   0,   0,   0,   1,   1,   1,   0,\n",
       "          0,   0,  13,   3, 353,   2,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,   1,   0,   1,   0,   9,   0,\n",
       "          1,  10,  11, 120,   5, 150,   0],\n",
       "       [ 40,   2,   1,   0,   0,   0,   0,   0,   0,   1,   2,   2,   0,\n",
       "          3,   6, 102,  31,   4,   3,  54]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(twenty_test.target, predicted_mnb_stemmed)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo más simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos algunas métricas sobre la matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.50      1.00      0.67         1\n",
      "    class 1       0.00      0.00      0.00         1\n",
      "    class 2       1.00      0.67      0.80         3\n",
      "\n",
      "avg / total       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: Los promedios se calculan utilizando el valor de la métrica para cada clase, pesado por el soporte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de 20 newsgroups..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.81      0.66      0.73       319\n",
      "           comp.graphics       0.78      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.82      0.69      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.69      0.80      0.74       392\n",
      "   comp.sys.mac.hardware       0.86      0.82      0.84       385\n",
      "          comp.windows.x       0.86      0.79      0.83       395\n",
      "            misc.forsale       0.88      0.75      0.81       390\n",
      "               rec.autos       0.87      0.93      0.90       396\n",
      "         rec.motorcycles       0.92      0.96      0.94       398\n",
      "      rec.sport.baseball       0.93      0.92      0.92       397\n",
      "        rec.sport.hockey       0.90      0.98      0.94       399\n",
      "               sci.crypt       0.71      0.97      0.82       396\n",
      "         sci.electronics       0.83      0.66      0.73       393\n",
      "                 sci.med       0.92      0.79      0.85       396\n",
      "               sci.space       0.82      0.94      0.88       394\n",
      "  soc.religion.christian       0.60      0.97      0.74       398\n",
      "      talk.politics.guns       0.65      0.94      0.77       364\n",
      "   talk.politics.mideast       0.92      0.94      0.93       376\n",
      "      talk.politics.misc       0.94      0.48      0.64       310\n",
      "      talk.religion.misc       0.95      0.22      0.35       251\n",
      "\n",
      "             avg / total       0.83      0.81      0.80      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(twenty_test.target, predicted_mnb_stemmed, target_names=twenty_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero descargamos el dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n"
     ]
    }
   ],
   "source": [
    "twenty_all = fetch_20newsgroups(subset='all', shuffle=True)\n",
    "print(len(twenty_all.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el método **train_test_split** que recibe el porcentaje de datos que queremos para prueba (o entrenamiento) y devuelve los datos separados en instancias (y clases) para prueba y para entrenamiento (de forma aleatoria y estratificada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos de entrenamiento:  15076\n",
      "Cantidad de datos de prueba:  3770\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(twenty_all.data, twenty_all.target, test_size=0.20)\n",
    "\n",
    "print(\"Cantidad de datos de entrenamiento: \",len(X_train))\n",
    "print(\"Cantidad de datos de prueba: \",len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8538461538461538\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "\n",
    "import numpy as np\n",
    "print(np.mean(predicted == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma más sencilla de usar la validación cruzada es utilizar función **cross_val_score** en el estimador y el conjunto de datos.\n",
    "\n",
    "El siguiente ejemplo muestra cómo estimar la precisión de un clasificador bayesiano, ajustando un modelo y calculando el score 5 veces consecutivas (con diferentes divisiones cada vez):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85456954 0.86164856 0.85623342 0.84997345 0.84742158]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "twenty_all = fetch_20newsgroups(subset='all', shuffle=True)\n",
    "X = TfidfVectorizer()\n",
    "X = X.fit_transform(twenty_all.data)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X, twenty_all.target, cv=5)\n",
    "\n",
    "print(scores)                                              "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos calcular entonces la media y el intervalo de confianza del 95% de cada uno de los clasificadores individuales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, el score calculado en cada iteración de CV es el método de score del estimador. Es posible cambiar esto usando el parámetro **score**. Por ejemplo podemos calcular la métrica F1 $$F1 = 2 * (precision * recall) / (precision + recall)$$\n",
    "\n",
    "En este caso, en que la clasificación no es binaria, se debe calcular un promedio para las diferentes clases. Para determinar cómo se calcula este promedio, hay diferentes opciones\n",
    "\n",
    "**micro**: Calcula la métrica globalmente contando el total de verdaderos positivos, falsos negativos y falsos positivos.\n",
    "\n",
    "**macro**: Calcula la métrica para cada etiqueta y luego calcula la media. No considera desbalance de clases.\n",
    "\n",
    "**weighted**: Calcula la métrica para cada etiqueta, calcula el promedio y los pesa por soporte (la cantidad de instancias verdaderas para cada etiqueta. Esto lo diferencia de **macro** para tener en cuenta el desbalance de clases. Puede resultar en un valor F-score que no se encuentre entre el valor de precisión y el valor de recall\n",
    "\n",
    "**samples**: Calcula la métrica por cada instancia, y luego calcula el promedio (solo tiene sentido para clasificación multietiqueta donde este valor difiere del accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84216861 0.83827895 0.83653434 0.83566105 0.83873968]\n"
     ]
    }
   ],
   "source": [
    "scores_f1 = cross_val_score(clf, X_train_tfidf, twenty_train.target, cv=5, scoring='f1_weighted')\n",
    "print(scores_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos diferentes tipos de validación cruzada: No estratificada, estratificada y aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83457052 0.81808539 0.8236542 ]\n",
      "[0.83470199 0.82374768 0.82156134]\n",
      "[0.85865724 0.84452297 0.85070671]\n",
      "\n",
      "Accuracy K-Fold: 0.825 (+/- 0.014)\n",
      "Accuracy Stratified K-Fold: 0.827 (+/- 0.011)\n",
      "Accuracy Suffle Split: 0.851 (+/- 0.012)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv_kfold = KFold(n_splits=3)\n",
    "cv_strat = StratifiedKFold(n_splits=3)\n",
    "cv_suffle = ShuffleSplit(n_splits=3)\n",
    "\n",
    "scores_kfold = cross_val_score(clf, X_train_tfidf, twenty_train.target, cv=cv_kfold)\n",
    "scores_strat = cross_val_score(clf, X_train_tfidf, twenty_train.target, cv=cv_strat)\n",
    "scores_suffle = cross_val_score(clf, X_train_tfidf, twenty_train.target, cv=cv_suffle)\n",
    "\n",
    "print(scores_kfold)\n",
    "print(scores_strat)\n",
    "print(scores_suffle)\n",
    "print()\n",
    "print(\"Accuracy K-Fold: %0.3f (+/- %0.3f)\" % (scores_kfold.mean(), scores_kfold.std() * 2))\n",
    "print(\"Accuracy Stratified K-Fold: %0.3f (+/- %0.3f)\" % (scores_strat.mean(), scores_strat.std() * 2))\n",
    "print(\"Accuracy Suffle Split: %0.3f (+/- %0.3f)\" % (scores_suffle.mean(), scores_suffle.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "La función **cross_validate** difiere de **cross_val_score** de dos maneras:\n",
    "\n",
    "1. Permite especificar múltiples métricas para la evaluación.\n",
    "2. Devuelve un dict que contiene los scores de entrenamiento, tiempos de entrenamiento, tiempos de calcuar los scores y los scores de la prueba.\n",
    "\n",
    "Si evaluamos una unica métrica (pasando un string al parámetro score, una función o None), las claves serán - ['test_score', 'fit_time', 'score_time']\n",
    "\n",
    "Si evaluamos múltiples métricas, el valor de retorno es un dict con las siguientes claves: ['test_ <scorer1_name>', 'test_ <scorer2_name>', 'test_ <scorer ...>', 'fit_time', 'score_time']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.32739472, 0.27578306, 0.26429963, 0.22309256, 0.25033712]),\n",
       " 'score_time': array([0.09475279, 0.09725761, 0.09023929, 0.06020212, 0.059659  ]),\n",
       " 'test_precision_macro': array([0.87766701, 0.87604061, 0.87798795, 0.87708132, 0.88266551]),\n",
       " 'test_recall_macro': array([0.83275965, 0.82696938, 0.82694664, 0.82367647, 0.82724057])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = MultinomialNB()\n",
    "scores = cross_validate(clf, X_train_tfidf, twenty_train.target, scoring=scoring, cv=5, return_train_score=False)\n",
    "scores\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Descargar el siguiente dataset:\n",
    " - http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
    "2. Escribir un Pipeline que permita clasificar las reviews de las películas como positivas o negativas.\n",
    "3. Buscar una buena configuración de parámetros para el clasificador elegido utilizando grid search.\n",
    "4. Evaluar la performance del clasificador utilizando la técnica de hold out (75/25)\n",
    "5. Evaluar la performance del clasificador utilizando validación cruzada.\n",
    "\n",
    "Nota: para cargar documentos de texto con categorías, scikit-learn provee el método **load_files(data_folder)**, que asume que dentro de \"data_folder\" hay una carpeta por cada clase posible, y dentro de esa carpeta se encuentran los documentos de texto plano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
